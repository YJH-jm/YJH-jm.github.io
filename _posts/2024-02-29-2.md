---
layout: single
title:  "RetinaFace: : Single-Shot Multi-Level Face Localisation in the Wild" # 글 제목
categories: 
  - Face Recognition # category
tags: [face detection ] # tag
toc: true # 오른쪽의 table of contents
toc_sticky: true # 스크롤 내려도 toc 고정
toc_label: 목차
author_profile: false
# sidebar: # 왼쪽 사이드 바
    # nav: "docs"
search: true # 글 검색 안됨
use_math: true
typore-root-url: ../
---

****



### RetinaFace: Single-Shot Multi-Level Face Localisation in the Wild

(CVPR 2020)

[논문](https://arxiv.org/pdf/1905.00641.pdf)



<br>

![image-20240312094307572](/images/2024-02-29-2/image-20240312094307572.png)

<br><br>

#### Abstract

**Single stage** 디자인으로새로운 pixel-wise face  localisation 방법을 제시

**Multi-task learning** 을 이용하여 각 pixel에 대응되는  face score, face box, 5개의 facial landmarks, 3D position 를 예측

- 다양한 task의 loss를 이용하여 학습 진행

WIDER FACE hard 데이터에서 RetinaFace가 그 당시의 SOTA인 ISRN 보다 성능이 좋아짐

IJB-C 데이터셋에서 ArcFace의 face verification의 정확도를 높이는데 도움

- Face  localisation 성능이 높아지면 face recognition 성능이 좋아짐을 확인 

가벼운 backbone 모델을 사용하면서 VGA resolution 이미지가 Single CPU core에서 실시간으로 동작하는 것을 확인



<br><br>



#### Related works

![1](/images/2024-02-29-2/1.jpeg)

<center style="font-size:12px;">
    <a href="https://wikidocs.net/162976"> 출처 </a>
</center>

##### Image Pyramid

이미지 해상도를 다르게 하여 피라미드 형태로 나타낸 것 

이미지 피라미드를 학습하면 다양한 해상도의 이미지를 학습하기 때문에 다양한 크기의 물건 잘 인식

각 이미지 해상도 별로 prediction 과정을 진행한다는 단점

<br>

#####  Feature Pyramid

위의 단점을 해결하기 위해 feature  pyramid를 이용할 수 있음 

한 번의 학습으로 각각을 prediction 진행 가능

Low-level 부터 high-level feature를 다 이용 가능 



 <br>

##### Context Modeling

다양한 feature를 input으로 받음

작은 얼굴도 잘 잡아 낼 수 있도록 모델의 contextual reasoning 키우는 역할



![Screenshot from 2024-03-12 10-09-43](/images/2024-02-29-2/Screenshot from 2024-03-12 10-09-43.png)



<br>

**Deformable Convolution**을 이용하여 진행

​	![newest](/images/2024-02-29-2/newest.png)

<center style="font-size:12px;">
    <a href="https://paperswithcode.com/method/deformable-convolution"> 출처 </a>
</center>

- 일반 convolution과 차이가 있음 

- 일반적인 커널에 offset을 주어 convolution 연산을 진행

- Receptive field가 더 넓어진다는 장점이 있음



<br>

##### Multi-task learning

Main task가 있다면 (여기서는 face detection)  sub task를 추가하여 학습하여 main task도 학습이 더 잘 되도록 하는 방법 

Mask R-CNN이 가장 대표적인 예시이고 main task인 object detection의 성능이 높이기 위해서 segmentation을 sub task로 이용 



<br>

<br>



#### RetinaFace

##### Multi-task Loss

여러 loss의 합으로 구성이 되고 각 요소의 중요도 마다 $ \lamda $ 를 주어서 가중치를 줌 

<br>

![image-20240312094307572](/images/2024-02-29-2/image-20240312094307572.png)

<br>

$$
L=L_{cls}(p_{i}, p_{i}^{*}) + \lambda_{1}p_{i}^{*}L_{box}(t_{i}, t_{i}^{*})
+ \lambda_{2}p_{i}^{*}L_{pts}(l_{i}, l_{i}^{*}) + \lambda_{3}p_{i}^{*}L_{pixel}
$$




1. Face classification loss  $L_{cls}(p_{i}, p_{i}^{*})$
   - 얼굴인지 아닌지 2개의 값으로 나타내어서 
2. Face box regression loss $L_{box}(t_{i}, t_{i}^{*})$
   - 얼굴의 좌표 4가지를 이용하여 face box regression loss 계산
3. Facial landmark regression loss $L_{pts}(l_{i}, l_{i}^{*})$
   - Retina Face는 5개의 landmark를 구하고 그것에 따른 좌표 2개의 값, 총 10개의 좌표에 대한 loss function
4. Dense regression loss $L_{pixel}$
   - 3D  mesh render에서 2D face로 regression 해주는 loss function



<br>



##### Dense Regression Branch



![Screenshot from 2024-03-12 11-28-21](/images/2024-02-29-2/Screenshot from 2024-03-12 11-28-21.png)

<center style="font-size:12px;">
    <a href="https://arxiv.org/pdf/1904.03525.pdf"> 출처 </a>
</center>



정답이 없는 set을 이용하여 reconstruction을 하는 task

Self-supervised Reconstruction Loss를 사용하여 학습



<br>

<br>

#### Experiments

##### Dataset : Wider Face

Face Detection Benchmark dataset

32,203 개의 이미지와 393,703개의 face box로 구성



<br>



![Screenshot from 2024-03-12 11-42-28](/images/2024-02-29-2/Screenshot from 2024-03-12 11-42-28.png)

<center style="font-size:12px;">
    <a href="http://shuoyang1213.me/WIDERFACE/WiderFace_Results.html"> 출처 </a>
</center>



<br>

Edge box라는 간단한 detection 모델을 사용해 confidence score 을 기준으로 데이터를 나눔

- Easy, Medium, Hard

![Screenshot from 2024-03-12 11-45-44](/images/2024-02-29-2/Screenshot from 2024-03-12 11-45-44.png)

<center style="font-size:12px;">
    <a href="https://arxiv.org/pdf/1511.06523.pdf"> 출처 </a>
</center>



Extra annotation 추가

- 5개의 landmark (눈, 코 , 입 가장자리)

![Screenshot from 2024-03-12 11-55-31](/images/2024-02-29-2/Screenshot from 2024-03-12 11-55-31.png)

<br>

##### Implementation details

1. Loss Head

   Multi-task loss는 Positive anchor에만 적용

2. Anchor settings

   Scale step은 $2^{\frac{1}{3}}$ 로 조절, Aspect ratio : 1 

   - 이미지 사이즈가 640  x 640 인경우에는 anchor가 16 x 16 ~ 406 x 406 까지  커버
   - 총 102,300개의 anchor가 존재하고 이 중 75%는 P2에 존재

   

   ![Screenshot from 2024-03-12 13-39-33](/images/2024-02-29-2/Screenshot from 2024-03-12 13-39-33.png){: .img-display-60 }

   - Feature pyramid 별로 anchor size가 다르게 적용 

   <br>

   Anchor와 ground-truth의 IOU가 0.5 이상이면 match , 0.3 미만이면 배경이라고 함

   Match 되지 않은 anchor는 학습에서 제외

   

   <br>

   Anchor는 학습의 비율을 맞추기 위해 Positive : Negative 를 3 : 1로 맞춤

   - OHEM (Online Hard Example Mining) 을 이용하여 맞춤

   

3. Data augmentation

   Random crop

   Horizontal flip

   Photo-metric color distortion

4. Training

   Optimizer : SGD

   Momentum : 0.9

   Weight decay :5e-4

   Batch size : 8 x 4

   Learning rate : 0.001

   Epochs : 80

   GPU : NVIDIA Tesla P40 (24GB) * 4

5. Testing

   Flip

   Multi-scale : [500, 800, 1100, 1400, 1700]

   IoU : 0.4

<br>



##### Ablation Study

![Screenshot from 2024-03-12 14-03-28](/images/2024-02-29-2/Screenshot from 2024-03-12 14-03-28.png){: .img-display-60 }

<br>

##### Face Recognition Accuracy

![Screenshot from 2024-03-12 14-08-59](/images/2024-02-29-2/Screenshot from 2024-03-12 14-08-59.png){: .img-display-60 }

RetinaFace를 사용하는 경우 Face verification 정확도가 증가



##### Inference Efficiency

![Screenshot from 2024-03-12 14-12-45](/images/2024-02-29-2/Screenshot from 2024-03-12 14-12-45.png){: .img-display-60 }

RetinaFace의 backbone과 Input Image의 화질에 따라 걸리는 시간



<br><br>



#### Conclusion

Wider Face 데이터에 5개의 추가적인 annotation을 넣어 학습을 하여 성능을 높임

Self-supervised branch를 추가해서 Face detection 성능을 높임

Wider Face hard set에서도 SOTA 정도의 성능을 보임

Face Verification의 성능을 높임

가벼운 backbone을 가지고 있어 single CPU core에석도 VGA 해상도 이미지에 대해서 실시간으로 추론이 가능 



<br><br>

 

### RetinaFace 코드 실행

Docker Image : pytorch/pytorch:2.0.0-cuda11.7-cudnn8-devel 

GPU : NVIDIA GeForce RTX 4080 Laptop GPU

코드 : [깃허브 주소](https://github.com/biubug6/Pytorch_Retinaface.git) 

- [공식 깃허브](https://github.com/deepinsight/insightface/tree/master/detection/retinaface)를 사용하지 않음 



#### Training

Wider Face 데이터를 이용하여 학습 진행





#### Inference

1. Dlib

   ![image-20240312145636951](/images/2024-02-29-2/image-20240312145636951.png){: .img-display-60 }

2. RetinaFace - CPU

   ![image-20240312150821833](/images/2024-02-29-2/image-20240312150821833.png){: .img-display-60 }

3. RetinaFace - GPU

   ![retina_img_gpu](/images/2024-02-29-2/retina_img_gpu.jpg){: .img-display-60 }





##### Inference 결과

Dlib으로 실행을 하면 CPU에서 진행하지만 FPS가 매우 빠르지만 Detection 정확도가 떨어짐

같은 CPU 환경에서 RetinaFace를 진행하면 속도는 느리지만 Detection 정확도가 매우 높은 것을 확인 할 수 있음

그렇지만 GPU에서 진행을 하면 지금 내가 실행한 코드에서는 병목현상이 발생하는지 매우 느려지는 것을 확인

이미지가 GPU에 올라가는 중에 생기나..? 수정 후 확인해야 할 듯 

